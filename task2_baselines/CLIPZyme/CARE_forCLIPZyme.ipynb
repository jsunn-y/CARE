{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from clipzyme import CLIPZyme\n",
    "from clipzyme import ReactionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Run this from the CLIPZyme directory\n",
    "\n",
    "Set the variable below as the absolute path to your CARE directory (ending in `/CARE`). Follow instructions to install CLIPZyme but instead install clipzyme package with `python -m pip install -e .`\n",
    "\n",
    "For training, replacing `clipzyme/datasets/enzymemap.py` with the version provided in CARE. You can also remove the validation dataloader in `scripts/main.py` to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARE_directory = '/disk1/jyang4/repos/CARE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swissprot = pd.read_csv(f'{CARE_directory}processed_data/protein2EC_clustered50.csv')\n",
    "uniprot_ids = swissprot['Entry'].unique()\n",
    "file_paths = [f\"gs://public-datasets-deepmind-alphafold-v4/AF-{u}-F1-model_v4.cif\" for u in uniprot_ids]\n",
    "output_file = 'uniprot_cif_paths.txt' \n",
    "\n",
    "with open(output_file, 'w') as file:\n",
    "    file.write('\\n'.join(file_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the AF2 database structures from google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat uniprot_cif_paths.txt | gsutil -m cp -I files/AF_structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Step 1: Training\n",
    "\n",
    " Move the configs from the CARE repo to `configs/train/` in the CLIPZyme repo. Train three different models for each of the different splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/dispatcher.py -c configs/train/CARE_clip_egnn_easy.json -l ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert CARE splits to the format for CLIPZyme inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reaction(reaction):\n",
    "    reactants, products = reaction.split(\">>\")\n",
    "    reactants = reactants.split(\".\")\n",
    "    products = products.split(\".\")\n",
    "\n",
    "    reactants = [r for r in reactants if r != \"[H+]\"]\n",
    "    products = [p for p in products if p != \"[H+]\"]\n",
    "\n",
    "    reaction_string = \"{}>>{}\".format(\".\".join(reactants), \".\".join(products))\n",
    "    return reaction_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"easy_reaction_test\", \"medium_reaction_test\", \"hard_reaction_test\"]:\n",
    "\n",
    "    df = pd.read_csv(f'{CARE_directory}/splits/task2/{dataset}.csv')\n",
    "    df.rename(columns={\"Mapped Reaction\": \"reaction\"}, inplace=True)\n",
    "    df[\"reaction\"] = df[\"reaction\"].apply(process_reaction)\n",
    "    df = pd.DataFrame(df[\"reaction\"])\n",
    "\n",
    "    #filler values\n",
    "    df[\"sequence\"] = \"MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENARIQSKLSDLQKKKIDIDNKLLKEKQNLIKEEILERKKLEVLTKKQQKDEIEHQKKLKREIDAIKASTQYITDVSISSYNNTIPETEPEYDLFISHASEDKEDFVRPLAETLQQLGVNVWYDEFTLKVGDSLRQKIDSGLRNSKYGTVVLSTDFIKKDWTNYELDGLVAREMNGHKMILPIWHKITKNDVLDYSPNLADKVALNTSVNSIEEIAHQLADVILNR\"\n",
    "    df[\"protein_id\"] = \"A0A009IHW8\"\n",
    "    df[\"cif\"] = \"files/AF_structures/AF-A0A009IHW8-F1-model_v4.cif\"\n",
    "\n",
    "    df.to_csv(f'files/{dataset}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{CARE_directory}/processed_data/protein2EC_clustered50.csv\")\n",
    "df.rename(columns={\"Sequence\": \"sequence\", \"Entry\": \"protein_id\"}, inplace=True)\n",
    "df[\"cif\"] = df[\"protein_id\"].apply(lambda x: f\"files/AF_structures/AF-{x}-F1-model_v4.cif\")\n",
    "\n",
    "df[\"reaction\"] = \"[CH2:1]=[CH:2][CH2:3][N:4]1[CH2:5][CH2:6][C@:7]23[c:8]4[c:9]5[cH:10][cH:11][c:12]([OH:13])[c:14]4[O:15][C@H:16]2[C@@H:17]([OH:18])[CH2:19][CH2:20][C@@:21]3([OH:22])[C@H:23]1[CH2:24]5.[NH2:25][C:26](=[O:27])[c:28]1[cH:29][cH:30][cH:31][n+:32]([C@@H:33]2[O:34][C@H:35]([CH2:36][O:37][P:38](=[O:39])([OH:40])[O:41][P:42](=[O:43])([OH:44])[O:45][CH2:46][C@H:47]3[O:48][C@@H:49]([n:50]4[cH:51][n:52][c:53]5[c:54]([NH2:55])[n:56][cH:57][n:58][c:59]45)[C@H:60]([O:61][P:62](=[O:63])([OH:64])[OH:65])[C@@H:66]3[OH:67])[C@@H:68]([OH:69])[C@H:70]2[OH:71])[cH:72]1>>[CH2:1]=[CH:2][CH2:3][N:4]1[CH2:5][CH2:6][C@:7]23[c:8]4[c:9]5[cH:10][cH:11][c:12]([OH:13])[c:14]4[O:15][C@H:16]2[C:17](=[O:18])[CH2:19][CH2:20][C@@:21]3([OH:22])[C@H:23]1[CH2:24]5.[NH2:25][C:26](=[O:27])[C:28]1=[CH:72][N:32]([C@@H:33]2[O:34][C@H:35]([CH2:36][O:37][P:38](=[O:39])([OH:40])[O:41][P:42](=[O:43])([OH:44])[O:45][CH2:46][C@H:47]3[O:48][C@@H:49]([n:50]4[cH:51][n:52][c:53]5[c:54]([NH2:55])[n:56][cH:57][n:58][c:59]45)[C@H:60]([O:61][P:62](=[O:63])([OH:64])[OH:65])[C@@H:66]3[OH:67])[C@@H:68]([OH:69])[C@H:70]2[OH:71])[CH:31]=[CH:30][CH2:29]1\"\n",
    "df.to_csv(\"files/protein2EC_clustered50.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the dispatcher to extract representations for reactions and proteins\n",
    "Move relevant configs from the CARE repo the the CLIPZyme repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract protein representations\n",
    "!python scripts/dispatcher.py -c configs/screening_proteins_easy.json -l ./logs/screening/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract reaction representations\n",
    "!python scripts/dispatcher.py -c configs/screening_reactions_easy.json -l ./logs/screening/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the reactions and proteins will not be successfully loaded by the dataset. Just drop these for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the extracted representations\n",
    "\n",
    "functions to process protein and reaction representations. Skip the missing embedding and merge the proteins by cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_proteins(split):\n",
    "    path = 'results/CARE_protein/last/{}'.format(split)\n",
    "\n",
    "    df = pd.read_csv('files/protein2EC_clustered50.csv')\n",
    "    length = len(df)\n",
    "    EClist = np.loadtxt(f\"{CARE_directory}/processed_data/EC_list.txt\", dtype=str)\n",
    "\n",
    "    embeddings = np.zeros((length, 1280))\n",
    "    #concatenate all embeddings\n",
    "    failed = []\n",
    "    for i in range(length):\n",
    "        try:\n",
    "            embeddings[i] = torch.load(f'{path}/sample_sample_{i}.protein.pt')\n",
    "        except:\n",
    "            #print(f'{path}/sample_sample_{i}.protein.pt not found')\n",
    "            failed.append(i)\n",
    "            continue\n",
    "    \n",
    "    #print(len(failed))\n",
    "    df['index'] = df.index\n",
    "    #drop indices in failed\n",
    "    df = df.drop(failed)\n",
    "\n",
    "    ec2index = df.groupby('EC number')['index'].apply(list).to_frame().to_dict()['index']\n",
    "\n",
    "    cluster_centers = np.zeros((len(EClist), 1280))\n",
    "    for i, ec in enumerate(EClist):\n",
    "        #average together the embeddings for each EC number\n",
    "        try:\n",
    "            indices = ec2index[ec]\n",
    "            cluster_centers[i] = np.mean(embeddings[indices], axis=0)\n",
    "        except:\n",
    "            cluster_centers[i] = np.zeros(1280)\n",
    "    \n",
    "    results = {}\n",
    "    results[\"protein_repr_array\"] = cluster_centers\n",
    "    os.makedirs(f'{CARE_directory}/task2_baselines/CLIPZyme/output/{split}_split/representations', exist_ok=True)\n",
    "    np.save(f'{CARE_directory}/task2_baselines/CLIPZyme/output/{split}_split/representations/all_ECs_cluster_centers.npy', results)\n",
    "    \n",
    "    return cluster_centers\n",
    "\n",
    "def process_reactions(split):\n",
    "    path = 'results/CARE_reaction/last/' + split + '_reaction_test'\n",
    "\n",
    "    df = pd.read_csv('files/{}.csv'.format(split + '_reaction_test'))\n",
    "    length = len(df)\n",
    "\n",
    "    embeddings = np.zeros((length, 1280))\n",
    "    #concatenate all embeddings\n",
    "    failed = []\n",
    "    for i in range(length):\n",
    "        try:\n",
    "            embeddings[i] = torch.load(f'{path}/sample_sample_{i}.reaction.pt')\n",
    "        except:\n",
    "            #print(f'{path}/sample_sample_{i}.reaction.pt not found')\n",
    "            failed.append(i)\n",
    "            continue\n",
    "    \n",
    "    results = {}\n",
    "    results[\"reaction_repr_array\"] = embeddings\n",
    "    np.save(f'{CARE_directory}/task2_baselines/CLIPZyme/output/{split}_split/representations/{split}_reaction_test_representations.npy', results)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['easy', 'medium', 'hard']: # 'medium', 'hard'\n",
    "    cluster_centers = process_proteins(split)\n",
    "    embeddings = process_reactions(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is only an example\n",
    "### Alternative way to run inference (slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Loaded model from checkpoints/74d55ed2e3506862b41906157d03193c/last.ckpt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Loaded model from checkpoints/74d55ed2e3506862b41906157d03193c/last.ckpt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CLIPZyme(checkpoint_path=\"checkpoints/74d55ed2e3506862b41906157d03193c/last.ckpt\").to(\"cuda:1\")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading ESM model\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading ESM model\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dataset: 100%|██████████████████████████████████████| 29327/29327 [00:54<00:00, 539.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> \n",
       "        DATASET CREATED:\n",
       "        * Number of samples: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25277</span>\n",
       "        * Number of reactions: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "        * Number of proteins: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25160</span>\n",
       "        \n",
       "</pre>\n"
      ],
      "text/plain": [
       " \n",
       "        DATASET CREATED:\n",
       "        * Number of samples: \u001b[1;36m25277\u001b[0m\n",
       "        * Number of reactions: \u001b[1;36m1\u001b[0m\n",
       "        * Number of proteins: \u001b[1;36m25160\u001b[0m\n",
       "        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create protein dataset\n",
    "#-------------------------\n",
    "protein_dataset = ReactionDataset(\n",
    "  dataset_file_path = \"files/protein2EC_clustered50.csv\",\n",
    "  esm_dir = \"files/esm2_dir\",\n",
    "  protein_cache_dir = \"files/AF_graphs\", # optional, where to cache processed protein graphs\n",
    ")\n",
    "protein_dataloader = DataLoader(protein_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in protein_dataloader:\n",
    "  protein_hiddens = model.extract_protein_features(batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading ESM model\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading ESM model\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dataset: 100%|█████████████████████████████████████████| 393/393 [00:00<00:00, 1061.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> \n",
       "        DATASET CREATED:\n",
       "        * Number of samples: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">376</span>\n",
       "        * Number of reactions: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">376</span>\n",
       "        * Number of proteins: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "        \n",
       "</pre>\n"
      ],
      "text/plain": [
       " \n",
       "        DATASET CREATED:\n",
       "        * Number of samples: \u001b[1;36m376\u001b[0m\n",
       "        * Number of reactions: \u001b[1;36m376\u001b[0m\n",
       "        * Number of proteins: \u001b[1;36m1\u001b[0m\n",
       "        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create reaction dataset\n",
    "#-------------------------\n",
    "reaction_dataset = ReactionDataset(\n",
    "  dataset_file_path = \"files/easy_reaction_test.csv\",\n",
    "  esm_dir = \"files/esm2_dir\",\n",
    "  protein_cache_dir = \"files/AF_graphs\", # optional, where to cache processed protein graphs\n",
    ")\n",
    "reaction_dataloader = DataLoader(reaction_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:1! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m reaction_dataset:\n\u001b[0;32m----> 2\u001b[0m   reaction_hiddens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_reaction_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/modified_repos/CLIPZyme/clipzyme/lightning/clipzyme.py:367\u001b[0m, in \u001b[0;36mCLIPZyme.extract_reaction_features\u001b[0;34m(self, batch, reaction)\u001b[0m\n\u001b[1;32m    357\u001b[0m     reactions \u001b[38;5;241m=\u001b[39m [process_mapped_reaction(rxn) \u001b[38;5;28;01mfor\u001b[39;00m rxn \u001b[38;5;129;01min\u001b[39;00m reaction]\n\u001b[1;32m    358\u001b[0m     batch \u001b[38;5;241m=\u001b[39m default_collate(\n\u001b[1;32m    359\u001b[0m         [\n\u001b[1;32m    360\u001b[0m             {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m         ]\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/clipzyme/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/modified_repos/CLIPZyme/clipzyme/models/protmol.py:208\u001b[0m, in \u001b[0;36mEnzymeReactionCLIP.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_as_mol_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_as_reaction_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    207\u001b[0m ):\n\u001b[0;32m--> 208\u001b[0m     substrate_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_reaction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     substrate_features \u001b[38;5;241m=\u001b[39m substrate_features \u001b[38;5;241m/\u001b[39m substrate_features\u001b[38;5;241m.\u001b[39mnorm(\n\u001b[1;32m    210\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     )\n\u001b[1;32m    212\u001b[0m     output\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    213\u001b[0m         {\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m\"\u001b[39m: substrate_features,\n\u001b[1;32m    215\u001b[0m         }\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/modified_repos/CLIPZyme/clipzyme/models/protmol.py:140\u001b[0m, in \u001b[0;36mEnzymeReactionCLIP.encode_reaction\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_reaction\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m--> 140\u001b[0m     reactant_edge_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreactants\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m     ]  \u001b[38;5;66;03m# N x D, where N is all the nodes in the batch\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     product_edge_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwln(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproducts\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     ]  \u001b[38;5;66;03m# N x D, where N is all the nodes in the batch\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     dense_reactant_edge_feats \u001b[38;5;241m=\u001b[39m to_dense_adj(\n\u001b[1;32m    148\u001b[0m         edge_index\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreactants\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39medge_index,\n\u001b[1;32m    149\u001b[0m         edge_attr\u001b[38;5;241m=\u001b[39mreactant_edge_feats,\n\u001b[1;32m    150\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreactants\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch,\n\u001b[1;32m    151\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/clipzyme/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/modified_repos/CLIPZyme/clipzyme/models/chemprop.py:65\u001b[0m, in \u001b[0;36mDMPNNEncoder.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# initialize messages on edges\u001b[39;00m\n\u001b[1;32m     64\u001b[0m init_msg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x[edge_index[\u001b[38;5;241m0\u001b[39m]], edge_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 65\u001b[0m h0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_func(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_msg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# directed message passing over edges\u001b[39;00m\n\u001b[1;32m     68\u001b[0m h \u001b[38;5;241m=\u001b[39m h0\n",
      "File \u001b[0;32m~/miniconda3/envs/clipzyme/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/clipzyme/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:1! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
     ]
    }
   ],
   "source": [
    "for batch in reaction_dataset:\n",
    "  reaction_hiddens = model.extract_reaction_features(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipzyme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
