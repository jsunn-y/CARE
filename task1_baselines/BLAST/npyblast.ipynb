{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d87af8-596e-4591-916f-2c09fdabd065",
   "metadata": {},
   "source": [
    "# npyblast baseline\n",
    "\n",
    "For the first baselines we want to generate accuracy, precision, recall and F1 score for each of the EC numbers.\n",
    "\n",
    "The first dataset is the price dataset.\n",
    "\n",
    "Requires: npysearch, sciutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d7fd6b3-16d9-410a-ba6e-63f53359829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15d402c1-a493-4259-ac7e-50064cc4f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sciutil import SciUtil\n",
    "u = SciUtil()\n",
    "\n",
    "base_dir = '/disk1/ariane/pycharm/CARE/'\n",
    "output_folder = f'{base_dir}task1_baselines/results_summary/BLAST/'\n",
    "\n",
    "def make_fastas():\n",
    "    filenames = [f'{base_dir}splits/task1/30-50_protein_test.csv', \n",
    "                 f'{base_dir}splits/task1/30_protein_test.csv', \n",
    "                 f'{base_dir}splits/task1/50-70_protein_test.csv',\n",
    "                 f'{base_dir}splits/task1/70-90_protein_test.csv',\n",
    "                 f'{base_dir}splits/task1/promiscuous_protein_test.csv',\n",
    "                 f'{base_dir}splits/task1/protein_train.csv',\n",
    "                 f'{base_dir}splits/task1/price_protein_test.csv']\n",
    "\n",
    "    for filename in filenames:\n",
    "        with open(filename.replace('.csv', '.fasta'), 'w') as f:\n",
    "            df = pd.read_csv(filename)\n",
    "            for entry, seq in df[['Entry', 'Sequence']].values:\n",
    "                f.write('>{}\\n{}\\n'.format(entry, seq))\n",
    "                     \n",
    "def get_uniprot2ec():\n",
    "    swissprot = pd.read_csv(f'{base_dir}processed_data/protein2EC.csv')\n",
    "    id2ec = swissprot.set_index('Entry')['EC number'].to_dict()\n",
    "    return id2ec\n",
    "\n",
    "def get_price2ec():\n",
    "    df = pd.read_csv(f'{base_dir}splits/task1/price_protein_test.csv')\n",
    "    id2ec = df.set_index('Entry')['EC number'].to_dict()\n",
    "    return id2ec\n",
    "    \n",
    "def get_default_training_fasta_path():\n",
    "    return f'{base_dir}splits/task1/protein_train.fasta'\n",
    "    \n",
    "def get_default_price_fasta_path():\n",
    "    return f'{base_dir}splits/task1/price_protein_test.fasta'\n",
    "\n",
    "def get_validation30():\n",
    "    return f'{base_dir}splits/task1/30_protein_test.fasta'\n",
    "\n",
    "def get_validation50():\n",
    "    return f'{base_dir}splits/task1/30-50_protein_test.fasta'\n",
    "    \n",
    "def get_validation70():\n",
    "    return f'{base_dir}splits/task1/50-70_protein_test.fasta'\n",
    "\n",
    "def get_validation90():\n",
    "    return f'{base_dir}splits/task1/70-90_protein_test.fasta'\n",
    "\n",
    "def get_promisc():\n",
    "    return f'{base_dir}splits/task1/promiscuous_protein_test.fasta'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4444501-ce68-4dba-a063-be2921d48566",
   "metadata": {},
   "source": [
    "## Make the default datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "530c932c-fcc8-4f93-8b56-c793d55cf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "make_fastas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944cff5-8239-42d7-9153-51d8f4003cb7",
   "metadata": {},
   "source": [
    "## Perform npysearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eff78f5f-ed23-444f-a8ae-eba63c44953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import npysearch as npy\n",
    "\n",
    "# task1_splits = ['30', '30-50', 'price', 'promiscuous']\n",
    "\n",
    "def get_test_fasta(label):\n",
    "    if label == 'price':\n",
    "        return get_default_price_fasta_path()\n",
    "    elif label == '30':\n",
    "        return get_validation30()\n",
    "    elif label == '30-50':\n",
    "        return get_validation50()\n",
    "    elif label == 'promiscuous':\n",
    "        return get_promisc()\n",
    "    else:\n",
    "        print(f'{label} not a valid dataset select one of ' + ' '.join(['30', '30-50', 'price', 'promiscuous']))\n",
    "\n",
    "\n",
    "def get_blast(test_label, num_ecs=1, min_identity=0.1, save=False):\n",
    "    \"\"\"\n",
    "    Gets the results for blast for a series of ECs and formats it correctly for the paper\n",
    "    \"\"\"\n",
    "    # Lets also look at the protein our query is the query genome and our database is going to be ecoli.\n",
    "    \n",
    "    results_prot = npy.blast(query=get_test_fasta(test_label),\n",
    "                             database=get_default_training_fasta_path(),\n",
    "                             minIdentity=min_identity,\n",
    "                             maxAccepts=num_ecs,\n",
    "                             alphabet=\"protein\")\n",
    "    results = pd.DataFrame(results_prot)  # Convert this into a dataframe so that we can see it more easily\n",
    "    results['predicted_ecs'] = results['TargetId'].map(get_uniprot2ec())\n",
    "    \n",
    "    if test_label == 'price':\n",
    "        results['true_ecs'] = results['QueryId'].map(get_price2ec())\n",
    "    else:\n",
    "        results['true_ecs'] = results['QueryId'].map(get_uniprot2ec())\n",
    "    grped = results.groupby('QueryId')\n",
    "    rows = []\n",
    "    for query, grp in grped:\n",
    "        # Always will be the same for the grouped \n",
    "        rows.append([query, grp['true_ecs'].values[0], grp['QueryMatchSeq'].values[0]] + list(grp['predicted_ecs'].values))\n",
    "    new_df = pd.DataFrame(rows)\n",
    "    new_df.columns = ['Entry', 'EC number', 'Sequence'] + list(range(0, num_ecs))\n",
    "\n",
    "    # Since we may have no similar ones we'll add in these as a dummy\n",
    "    new_df = new_df.fillna('0.0.0.0')\n",
    "    # Save to a file in the default location\n",
    "    if save:\n",
    "        new_df.to_csv(f'{output_folder}{test_label}_protein_test_results_df.csv', index=False)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f67cf3b-9020-4322-929c-bffe84046a10",
   "metadata": {},
   "source": [
    "## Map the targetID which is the prediction to the the predicted EC number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f88f8330-77aa-4b55-a8fd-53ff826cd17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (59 kB)                      \n",
      " Search database: 100.0% (175.0)                    \n",
      "      Write hits: 100.0% (1595.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (74 kB)                      \n",
      " Search database: 100.0% (196.0)                    \n",
      "      Write hits: 100.0% (1911.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (57 kB)                      \n",
      " Search database: 100.0% (146.0)                    \n",
      "      Write hits: 100.0% (1415.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (71 kB)                      \n",
      " Search database: 100.0% (179.0)                    \n",
      "      Write hits: 100.0% (1764.0)                    \r"
     ]
    }
   ],
   "source": [
    "# Save in the required format\n",
    "for split in ['30', '30-50', 'price', 'promiscuous']:\n",
    "    get_blast(split, 10, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e5390-5351-4a7a-b592-095733544089",
   "metadata": {},
   "source": [
    "## Compute accuracy for the prediction vs the true values for each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eae092b2-c3f8-4927-a7bb-721b8cfb548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m                                 Price dataset\t                                 \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mAcc level 1:\t73.97\t\n",
      "Acc level 2:\t71.23\t\n",
      "Acc level 3:\t62.33\t\n",
      "Acc level 4:\t35.62\t \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7397260273972602,\n",
       " 0.7123287671232876,\n",
       " 0.6232876712328768,\n",
       " 0.3561643835616438)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.dp(['Price dataset'])\n",
    "compute_accuracy_baseline1(results['predicted_ecs'].values, results['true_ecs'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc2fb8-0352-47cb-a47e-a5a7463e1818",
   "metadata": {},
   "source": [
    "## Do the same for each of the percentage splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfcf02bc-1d58-4507-96c5-ae79f8e9f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (59 kB)                      \n",
      " Search database: 100.0% (175.0)                    \n",
      "      Write hits: 100.0% (174.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m                                  30% dataset\t                                  \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mAcc level 1:\t63.22\t\n",
      "Acc level 2:\t55.75\t\n",
      "Acc level 3:\t53.45\t\n",
      "Acc level 4:\t50.57\t \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.632183908045977, 0.5574712643678161, 0.5344827586206896, 0.5057471264367817)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import npysearch as npy\n",
    "\n",
    "# Lets also look at the protein our query is the query genome and our database is going to be ecoli.\n",
    "results_prot = npy.blast(query=get_validation30(),\n",
    "                         database=get_default_training_fasta_path(),\n",
    "                         minIdentity=0.1,\n",
    "                         maxAccepts=1,\n",
    "                         alphabet=\"protein\")\n",
    "results = pd.DataFrame(results_prot)  # Convert this into a dataframe so that we can see it more easily\n",
    "\n",
    "results['predicted_ecs'] = results['TargetId'].map(get_uniprot2ec())\n",
    "results['true_ecs'] = results['QueryId'].map(get_uniprot2ec())\n",
    "u.dp(['30% dataset'])\n",
    "\n",
    "compute_accuracy_baseline1(results['predicted_ecs'].values, results['true_ecs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9406a258-9f3d-45ab-9a8d-da0e8e76e5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (74 kB)                      \n",
      " Search database: 100.0% (196.0)                    \n",
      "      Write hits: 100.0% (196.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m                                  50% dataset\t                                  \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mAcc level 1:\t93.88\t\n",
      "Acc level 2:\t90.31\t\n",
      "Acc level 3:\t87.24\t\n",
      "Acc level 4:\t84.18\t \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9387755102040817,\n",
       " 0.9030612244897959,\n",
       " 0.8724489795918368,\n",
       " 0.8418367346938775)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import npysearch as npy\n",
    "\n",
    "# Lets also look at the protein our query is the query genome and our database is going to be ecoli.\n",
    "results_prot = npy.blast(query=get_validation50(),\n",
    "                         database=get_default_training_fasta_path(),\n",
    "                         minIdentity=0.1,\n",
    "                         maxAccepts=1,\n",
    "                         alphabet=\"protein\")\n",
    "results = pd.DataFrame(results_prot)  # Convert this into a dataframe so that we can see it more easily\n",
    "\n",
    "results['predicted_ecs'] = results['TargetId'].map(get_uniprot2ec())\n",
    "results['true_ecs'] = results['QueryId'].map(get_uniprot2ec())\n",
    "u.dp(['50% dataset'])\n",
    "\n",
    "compute_accuracy_baseline1(results['predicted_ecs'].values, results['true_ecs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "512356cc-38ae-4372-9653-ce834dfe8f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m                                30-70% dataset\t                                 \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (74 kB)                      \n",
      " Search database: 100.0% (204.0)                    \n",
      "      Write hits: 100.0% (204.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m Acc level 1:\t99.02\t\n",
      "Acc level 2:\t96.08\t\n",
      "Acc level 3:\t94.61\t\n",
      "Acc level 4:\t90.2\t \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9901960784313726, 0.9607843137254902, 0.946078431372549, 0.9019607843137255)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets also look at the protein our query is the query genome and our database is going to be ecoli.\n",
    "results_prot = npy.blast(query=get_validation70(),\n",
    "                         database=get_default_training_fasta_path(),\n",
    "                         minIdentity=0.1,\n",
    "                         maxAccepts=1,\n",
    "                         alphabet=\"protein\")\n",
    "results = pd.DataFrame(results_prot)  # Convert this into a dataframe so that we can see it more easily\n",
    "u.dp(['30-70% dataset'])\n",
    "\n",
    "results['predicted_ecs'] = results['TargetId'].map(get_uniprot2ec())\n",
    "results['true_ecs'] = results['QueryId'].map(get_uniprot2ec())\n",
    "compute_accuracy_baseline1(results['predicted_ecs'].values, results['true_ecs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16f3c61e-c1af-43f2-88d6-4d63a935a796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m                                70-90% dataset\t                                 \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (75 kB)                      \n",
      " Search database: 100.0% (206.0)                    \n",
      "      Write hits: 100.0% (206.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mAcc level 1:\t99.03\t\n",
      "Acc level 2:\t99.03\t\n",
      "Acc level 3:\t99.03\t\n",
      "Acc level 4:\t97.57\t \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9902912621359223,\n",
       " 0.9902912621359223,\n",
       " 0.9902912621359223,\n",
       " 0.9757281553398058)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets also look at the protein our query is the query genome and our database is going to be ecoli.\n",
    "results_prot = npy.blast(query=get_validation90(),\n",
    "                         database=get_default_training_fasta_path(),\n",
    "                         minIdentity=0.1,\n",
    "                         maxAccepts=1,\n",
    "                         alphabet=\"protein\")\n",
    "results = pd.DataFrame(results_prot)  # Convert this into a dataframe so that we can see it more easily\n",
    "u.dp(['70-90% dataset'])\n",
    "\n",
    "results['predicted_ecs'] = results['TargetId'].map(get_uniprot2ec())\n",
    "results['true_ecs'] = results['QueryId'].map(get_uniprot2ec())\n",
    "compute_accuracy_baseline1(results['predicted_ecs'].values, results['true_ecs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db5eb109-74c8-4eed-9848-a16e7ed83eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m                              Promisuous dataset\t                               \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   Read database: 100.0% (58 MB)                    \n",
      "Analyze database: 100.0% (168k)                    \n",
      "  Index database: 100.0% (168k)                    \n",
      "    Read queries: 100.0% (71 kB)                      \n",
      " Search database: 100.0% (179.0)                    \n",
      "      Write hits: 100.0% (179.0)                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mAcc level 1:\t94.97\t\n",
      "Acc level 2:\t92.74\t\n",
      "Acc level 3:\t92.18\t\n",
      "Acc level 4:\t91.62\t \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9497206703910615,\n",
       " 0.9273743016759777,\n",
       " 0.9217877094972067,\n",
       " 0.9162011173184358)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets also look at the protein our query is the query genome and our database is going to be ecoli.\n",
    "results_prot = npy.blast(query=get_promisc(),\n",
    "                         database=get_default_training_fasta_path(),\n",
    "                         minIdentity=0.1,\n",
    "                         maxAccepts=1,\n",
    "                         alphabet=\"protein\")\n",
    "results = pd.DataFrame(results_prot)  # Convert this into a dataframe so that we can see it more easily\n",
    "u.dp(['Promisuous dataset'])\n",
    "\n",
    "results['predicted_ecs'] = results['TargetId'].map(get_uniprot2ec())\n",
    "results['true_ecs'] = results['QueryId'].map(get_uniprot2ec())\n",
    "compute_accuracy_baseline1(results['predicted_ecs'].values, results['true_ecs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37499121-9bda-4eac-9da0-4550097de2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4173c5-6305-4bd2-8673-2a5dceb01029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
